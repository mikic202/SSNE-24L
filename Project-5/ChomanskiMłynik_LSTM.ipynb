{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikic202/miniconda3/envs/pt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mikic202/miniconda3/envs/pt/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torch.utils.data import Subset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "corpus = api.load('text8')\n",
    "gensim_model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['review', 'rating'],\n",
      "    num_rows: 16392\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "review_dataset = load_dataset(\"csv\", data_files=\"data/train_data.csv\", split=\"train\")\n",
    "print(review_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = gensim_model.wv.key_to_index\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    review_tokenized = []\n",
    "    all_parsed = 0\n",
    "    unknows = 0\n",
    "    for word in examples.split():\n",
    "        all_parsed+=1\n",
    "        try:\n",
    "            review_tokenized.append(tokenizer[word.lower()])\n",
    "        except:\n",
    "            unknows +=1\n",
    "#     print(unknows/all_parsed)\n",
    "    return review_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        data['review'] = torch.tensor(tokenize_function(data['review']))\n",
    "        return data\n",
    "        # words_to_delete = int(len(data['input_ids']) * 0.99)\n",
    "        # text_indecies, _ = random_split(\n",
    "        #     range(len(data['input_ids'])), [words_to_delete, len(data['input_ids']) - words_to_delete]\n",
    "        # )\n",
    "        # return {'rating': data['rating'], 'input_ids': data['input_ids'][text_indecies], 'attention_mask': data['attention_mask'][text_indecies]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets = review_dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_datasets = tokenized_datasets.remove_columns([\"review\"])\n",
    "# tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "torch.manual_seed(73)\n",
    "n_train_examples = int(len(review_dataset) * 0.9)\n",
    "train_indices, validation_indices = random_split(\n",
    "    range(len(review_dataset)), [n_train_examples, len(review_dataset) - n_train_examples]\n",
    ")\n",
    "review_dataset.set_format(\"torch\")\n",
    "\n",
    "validation_dataset = CustomDataset(Subset(review_dataset, validation_indices))\n",
    "train_dataset = CustomDataset(Subset(review_dataset, train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def pad_collate(batch):\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for pack in batch:\n",
    "        xx.append(pack['review'])\n",
    "        yy.append(pack['rating'])\n",
    "    x_lens = [len(x)-1 for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy = torch.stack(yy)\n",
    "    return xx_pad, yy, x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn=pad_collate)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (embeddings): Embedding(71290, 100)\n",
       "  (lstm): LSTM(100, 500, num_layers=2)\n",
       "  (fc): Linear(in_features=500, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights = torch.FloatTensor(gensim_model.wv.vectors)\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size, emb_weights, bidirectional = False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if bidirectional:\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.embeddings = nn.Embedding.from_pretrained(emb_weights)\n",
    "        self.embeddings.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size*self.bidirectional, out_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "\n",
    "    def forward(self, x, len_x, hidden):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        last_seq_items = all_outputs[range(all_outputs.shape[0]), len_x]\n",
    "        out = last_seq_items # torch.flatten(all_outputs,1)\n",
    "        x = self.fc(out)\n",
    "        return x, hidden\n",
    "\n",
    "lstm_model = LSTMRegressor(100, 500, 2, 5, emb_weights).to(device)\n",
    "lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [01:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [01:02<00:00,  3.70it/s]\n",
      "100%|██████████| 231/231 [01:03<00:00,  3.66it/s]\n",
      "100%|██████████| 231/231 [01:04<00:00,  3.58it/s]\n",
      "100%|██████████| 231/231 [01:04<00:00,  3.57it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.50it/s]\n",
      "100%|██████████| 231/231 [01:06<00:00,  3.47it/s]\n",
      "100%|██████████| 231/231 [01:04<00:00,  3.56it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.53it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.52it/s]\n",
      "100%|██████████| 231/231 [01:06<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [01:06<00:00,  3.50it/s]\n",
      "100%|██████████| 231/231 [01:06<00:00,  3.47it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.50it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.52it/s]\n",
      "100%|██████████| 231/231 [01:06<00:00,  3.46it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.51it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.52it/s]\n",
      "100%|██████████| 231/231 [01:06<00:00,  3.49it/s]\n",
      "100%|██████████| 231/231 [01:05<00:00,  3.52it/s]\n",
      "100%|██████████| 231/231 [01:11<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 0.001)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "lstm_model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(21):\n",
    "    losses = 0\n",
    "    batches = 0\n",
    "    for x, targets, len_x in tqdm(review_train_loader):\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = lstm_model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device)\n",
    "        preds, _ = lstm_model(x, len_x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        batches +=1\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {losses/batches:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5469512195121952}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    for x, targets, len_x in validation_dataloader:\n",
    "        x = x.to(device)\n",
    "        targets_list.append(targets.numpy())\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = lstm_model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device)\n",
    "        preds, _ = lstm_model(x, len_x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        metric.add_batch(predictions=torch.argmax(preds, dim=-1), references=targets)\n",
    "\n",
    "metric.compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm_model = LSTMRegressor(100, 100, 1, 5, emb_weights).to(device)\n",
    " Po 50 epokach accuracy 54%\n",
    "\n",
    "\n",
    "LSTMRegressor(100, 500, 2, 5, emb_weights).to(device)\n",
    " Po 20 epokach 54,6%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
